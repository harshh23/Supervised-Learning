{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Program 12**"
      ],
      "metadata": {
        "id": "nUV_cZ3JNnJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare a model for prediction of survival from Titanic Ship using Random Forest and compare the accuracy with other classifiers also."
      ],
      "metadata": {
        "id": "NyE-dQeBNm-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"titanic.csv\")\n",
        "\n",
        "# Drop rows where the target variable is missing\n",
        "df = df.dropna(subset=['Survived'])\n",
        "\n",
        "# Select features 'x' and target variable 'y'\n",
        "x = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
        "y = df[\"Survived\"]\n",
        "\n",
        "# Encode categorical feature 'Sex' to numeric\n",
        "le = LabelEncoder()\n",
        "x['Sex'] = le.fit_transform(x['Sex'])\n",
        "\n",
        "# Fill missing values in 'Age' with the mean\n",
        "x['Age'] = x['Age'].fillna(x['Age'].mean())\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a Random Forest Classifier with 100 decision trees\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the Random Forest Classifier\n",
        "rf_model.fit(x_train, y_train)\n",
        "\n",
        "# Make predictions using the Random Forest Classifier\n",
        "y_pred_rf = rf_model.predict(x_test)\n",
        "\n",
        "# Evaluate the Random Forest Classifier\n",
        "rf_accuracy = accuracy_score(y_test, y_pred_rf)\n",
        "rf_classification_report = classification_report(y_test, y_pred_rf)\n",
        "\n",
        "print(\"Accuracy of Random Forest Classifier: \", rf_accuracy)\n",
        "print(\"Classification Report:\\n\", rf_classification_report)\n",
        "\n",
        "# Comparison with other Models\n",
        "\n",
        "# Initialize models\n",
        "model1 = KNeighborsClassifier(n_neighbors=9)\n",
        "model2 = GaussianNB()\n",
        "model3 = DecisionTreeClassifier(criterion='entropy')\n",
        "model4 = RandomForestClassifier(n_estimators=100)\n",
        "# List of models for comparison\n",
        "modellist = [model1, model2, model3, model4]\n",
        "\n",
        "# Evaluate each model\n",
        "print(\"\\n=== Model Comparison Results ===\")\n",
        "for model in modellist:\n",
        "    model.fit(x_train, y_train)\n",
        "    y_pred = model.predict(x_test)\n",
        "    # Calculate performance metrics\n",
        "    model_accuracy = accuracy_score(y_test, y_pred)\n",
        "    model_confusion_matrix = confusion_matrix(y_test, y_pred)\n",
        "    model_classification_report = classification_report(y_test, y_pred)\n",
        "    # Display results for each model\n",
        "    print(f\"\\nModel: {model.__class__.__name__}\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(model_confusion_matrix)\n",
        "    print(f\"Accuracy: {model_accuracy:.2f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(model_classification_report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xLOIWWO3avIL",
        "outputId": "44723c92-e87f-48ca-aadb-8a28865ba070"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Random Forest Classifier:  0.8156424581005587\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85       105\n",
            "           1       0.81      0.73      0.77        74\n",
            "\n",
            "    accuracy                           0.82       179\n",
            "   macro avg       0.81      0.80      0.81       179\n",
            "weighted avg       0.82      0.82      0.81       179\n",
            "\n",
            "\n",
            "=== Model Comparison Results ===\n",
            "\n",
            "Model: KNeighborsClassifier\n",
            "Confusion Matrix:\n",
            "[[85 20]\n",
            " [34 40]]\n",
            "Accuracy: 0.70\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.81      0.76       105\n",
            "           1       0.67      0.54      0.60        74\n",
            "\n",
            "    accuracy                           0.70       179\n",
            "   macro avg       0.69      0.68      0.68       179\n",
            "weighted avg       0.69      0.70      0.69       179\n",
            "\n",
            "\n",
            "Model: GaussianNB\n",
            "Confusion Matrix:\n",
            "[[85 20]\n",
            " [21 53]]\n",
            "Accuracy: 0.77\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.81      0.81       105\n",
            "           1       0.73      0.72      0.72        74\n",
            "\n",
            "    accuracy                           0.77       179\n",
            "   macro avg       0.76      0.76      0.76       179\n",
            "weighted avg       0.77      0.77      0.77       179\n",
            "\n",
            "\n",
            "Model: DecisionTreeClassifier\n",
            "Confusion Matrix:\n",
            "[[83 22]\n",
            " [21 53]]\n",
            "Accuracy: 0.76\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.79      0.79       105\n",
            "           1       0.71      0.72      0.71        74\n",
            "\n",
            "    accuracy                           0.76       179\n",
            "   macro avg       0.75      0.75      0.75       179\n",
            "weighted avg       0.76      0.76      0.76       179\n",
            "\n",
            "\n",
            "Model: RandomForestClassifier\n",
            "Confusion Matrix:\n",
            "[[91 14]\n",
            " [20 54]]\n",
            "Accuracy: 0.81\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.87      0.84       105\n",
            "           1       0.79      0.73      0.76        74\n",
            "\n",
            "    accuracy                           0.81       179\n",
            "   macro avg       0.81      0.80      0.80       179\n",
            "weighted avg       0.81      0.81      0.81       179\n",
            "\n"
          ]
        }
      ]
    }
  ]
}